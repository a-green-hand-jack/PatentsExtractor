# 改进的 PDF 提取脚本设计方案

本文档由 AI 助手创建，旨在规划和设计一个基于 `marker` 库的、功能增强的 PDF 文本提取脚本。

## 1. 摘要 (Summary)

本项目旨在取代现有的概念验证脚本 (`01_marker_poc.py`)，开发一个功能完备、配置灵活且性能更优的 PDF 批量处理脚本。新脚本将充分利用 `marker` 库提供的高级功能，如 LLM 增强、强制 OCR 和并行处理，以应对各种复杂的 PDF 文档，并产出高质量的 Markdown 文本。

## 2. 需求分析 (Requirements Analysis)

### 2.1. 现有脚本分析

现有的 `01_marker_poc.py` 脚本：
- **功能**: 能处理单个硬编码的 PDF 文件。
- **实现**: 直接调用 `marker` 的内部底层 API。
- **配置**: 使用默认配置，未启用任何高级功能。
- **局限性**: 缺乏灵活性，无法批量处理，未利用 `marker` 的核心优势。

### 2.2. 新脚本目标

新脚本将具备以下核心能力：
1.  **批量处理**: 支持对整个文件夹内的所有 PDF 文件进行批量转换。
2.  **高级功能集成**:
    - **LLM 增强 (`use_llm`)**: 集成 Google Gemini API 来提升表格和复杂结构的解析精度。
    - **强制 OCR (`force_ocr`)**: 为扫描件或文本质量差的 PDF 提供重新 OCR 的选项。
3.  **灵活配置**: 通过命令行参数轻松控制各项功能，如工作进程数、LLM 使用开关等。
4.  **健壮性**: 具备完善的错误处理和日志记录机制，能够跳过处理失败的文件并记录错误信息。
5.  **高性能**: 支持多进程并行处理，以最大化处理效率。
6.  **易用性**: 提供清晰的命令行接口和说明文档。

## 3. 设计方案 (Design Proposal)

我将创建一个名为 `02_advanced_marker_processor.py` 的新脚本，存放于 `scripts/` 目录下。

### 3.1. 技术选型

- **命令行接口**: 使用 Python 内置的 `argparse` 模块来构建用户友好的命令行界面。
- **路径管理**: 遵循项目规范，统一使用 `pathlib.Path` 对象处理文件路径。
- **日志系统**: 使用 `logging` 模块记录详细的运行时信息和错误。
- **依赖管理**: 敏感信息（如 API 密钥）将通过环境变量进行管理，符合十二要素应用原则。

### 3.2. 核心功能实现

#### 3.2.1. 命令行接口 (CLI)

脚本将支持以下命令行参数：

```bash
python scripts/02_advanced_marker_processor.py <input_dir> <output_dir> [options]
```

- **必选参数**:
    - `input_dir`: 包含待处理 PDF 文件的输入文件夹路径。
    - `output_dir`: 用于存放转换后的 Markdown 文件的输出文件夹路径。
- **可选参数 (`options`)**:
    - `--workers INT`: 并行处理的工作进程数 (默认为 2)。
    - `--use_llm`: 启用 LLM 增强功能 (默认关闭)。
    - `--force_ocr`: 对所有文档启用强制 OCR (默认关闭)。
    - `--max_files INT`: 要转换的最大文件数 (默认处理全部文件)。
    - `--log_file PATH`: 指定日志文件的输出路径 (默认为 `output_dir/processing.log`)。

#### 3.2.2. 配置与密钥管理

- **Google API Key**: `use_llm` 功能依赖于 Google Gemini API。脚本将从名为 `GOOGLE_API_KEY` 的环境变量中读取密钥。如果启用了 `--use_llm` 但未设置该环境变量，脚本将抛出错误并退出。

#### 3.2.3. 脚本执行流程

1.  **初始化**:
    - 解析命令行参数。
    - 配置日志系统，支持同时输出到控制台和文件。
    - 检查 `GOOGLE_API_KEY` 环境变量（如果 `--use_llm` 被激活）。
2.  **文件扫描**:
    - 扫描 `input_dir`，获取所有 `.pdf` 文件的列表。
    - 检查 `output_dir` 中是否已存在同名的 `.md` 文件，若存在则跳过，避免重复处理。
3.  **模型加载**:
    - 在主进程中预先加载一次 `marker` 模型。这将显著提升性能，因为模型将被所有子进程共享（通过写时复制机制），避免了每个进程重复加载的开销。
4.  **并行处理**:
    - 使用 Python 的 `concurrent.futures.ProcessPoolExecutor` 创建一个进程池。
    - 将待处理的 PDF 文件列表分发给工作进程。
    - 每个工作进程调用一个独立的转换函数，传入 PDF 路径、输出路径、模型对象和配置参数。
5.  **单个文件转换**:
    - 在工作进程中，调用 `marker.convert_pdf` 函数。
    - 根据命令行参数，动态传入 `use_llm` 和 `force_ocr` 等设置。
    - 捕获任何转换过程中发生的异常，记录详细错误日志，并继续处理下一个文件。
6.  **完成**:
    - 所有文件处理完毕后，主进程输出总结信息（如成功数、失败数、总耗时）。

## 4. 待确认事项 (Points for Confirmation)

在开始编码之前，希望与您确认以下几点：

1.  **脚本命名**: `02_advanced_marker_processor.py` 这个名称是否合适？
2.  **环境变量**: 要求用户必须通过设置 `GOOGLE_API_KEY` 环境变量来使用 LLM 功能，这个方案您是否同意？这是 `marker` 库推荐的做法，也是业界标准。
3.  **默认行为**:
    - 默认并行工作数设置为 `2`，这是一个比较保守和安全的选择。您是否有特定的性能要求？
    - 默认不启用 `--use_llm` 和 `--force_ocr`，让用户按需开启，您认为是否合理？
4.  **输出结构**: 将所有转换后的 `.md` 文件和日志文件都直接放在指定的 `output_dir` 中，这种扁平化的输出结构是否满足您的需求？

期待您的反馈！一旦我们对以上方案达成一致，我将立即开始编写代码。
